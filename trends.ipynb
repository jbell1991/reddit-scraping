{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from decouple import config\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import praw\n",
    "from profanity_filter import remove_bad_words\n",
    "from PIL import Image\n",
    "import psycopg2\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id = config(\"CLIENT_ID\"),\n",
    "    client_secret = config(\"SECRET\"),\n",
    "    user_agent = config(\"USER\"),\n",
    "    username = config(\"USERNAME\"),\n",
    "    password = config(\"PASSWORD\")\n",
    ")\n",
    "\n",
    "subreddit = reddit.subreddit(\"wallstreetbets\")\n",
    "\n",
    "hot_wsb = subreddit.hot(limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing data in a pandas dataframe\n",
    "dict = {\"title\": [],\n",
    "        \"subreddit\": [],\n",
    "        \"score\": [],\n",
    "        \"id\": [],\n",
    "        \"url\": [],\n",
    "        \"comms_num\": [],\n",
    "        \"created\": [],\n",
    "        \"body\": []}\n",
    "\n",
    "for submission in hot_wsb:\n",
    "    dict[\"title\"].append(submission.title)\n",
    "    dict['subreddit'].append(submission.subreddit)\n",
    "    dict[\"score\"].append(submission.score)\n",
    "    dict[\"id\"].append(submission.id)\n",
    "    dict[\"url\"].append(submission.url)\n",
    "    dict[\"comms_num\"].append(submission.num_comments)\n",
    "    dict[\"created\"].append(submission.created)\n",
    "    dict[\"body\"].append(submission.selftext)\n",
    "    \n",
    "df = pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that cleans the text in the submission\n",
    "def clean_submission(text):\n",
    "    text = text.lower()\n",
    "    text = ' '.join(\n",
    "        re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t'])|(\\w+:\\/\\/\\S+)\", \" \", text).split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(173, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>created</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>moves tomorrow april 27 2021</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>186</td>\n",
       "      <td>mz6iks</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>5492</td>\n",
       "      <td>1.619496e+09</td>\n",
       "      <td>daily trading discussion thread please keep sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>got feeling whole family going</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>10318</td>\n",
       "      <td>mz27qe</td>\n",
       "      <td>https://v.redd.it/tggz9iaosjv61</td>\n",
       "      <td>238</td>\n",
       "      <td>1.619485e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gme squeeze incoming</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>4845</td>\n",
       "      <td>mz69gk</td>\n",
       "      <td>https://i.redd.it/j0awzqpxnkv61.png</td>\n",
       "      <td>813</td>\n",
       "      <td>1.619495e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>even smallest person change course future</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>28801</td>\n",
       "      <td>myw1zz</td>\n",
       "      <td>https://v.redd.it/1v0moiy9civ61</td>\n",
       "      <td>625</td>\n",
       "      <td>1.619467e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rare copy melvil citadels medias bible</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>5913</td>\n",
       "      <td>myym53</td>\n",
       "      <td>https://i.redd.it/o7pqdntxziv61.jpg</td>\n",
       "      <td>147</td>\n",
       "      <td>1.619475e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title       subreddit  score      id  \\\n",
       "0               moves tomorrow april 27 2021  wallstreetbets    186  mz6iks   \n",
       "1             got feeling whole family going  wallstreetbets  10318  mz27qe   \n",
       "2                       gme squeeze incoming  wallstreetbets   4845  mz69gk   \n",
       "3  even smallest person change course future  wallstreetbets  28801  myw1zz   \n",
       "4     rare copy melvil citadels medias bible  wallstreetbets   5913  myym53   \n",
       "\n",
       "                                                 url  comms_num       created  \\\n",
       "0  https://www.reddit.com/r/wallstreetbets/commen...       5492  1.619496e+09   \n",
       "1                    https://v.redd.it/tggz9iaosjv61        238  1.619485e+09   \n",
       "2                https://i.redd.it/j0awzqpxnkv61.png        813  1.619495e+09   \n",
       "3                    https://v.redd.it/1v0moiy9civ61        625  1.619467e+09   \n",
       "4                https://i.redd.it/o7pqdntxziv61.jpg        147  1.619475e+09   \n",
       "\n",
       "                                                body  \n",
       "0  daily trading discussion thread please keep sh...  \n",
       "1                                                     \n",
       "2                                                     \n",
       "3                                                     \n",
       "4                                                     "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying clean submission function to the title and body columns\n",
    "df['title'] = df['title'].apply(lambda x: clean_submission(x))\n",
    "df['body'] = df['body'].apply(lambda x: clean_submission(x))\n",
    "\n",
    "body_text = \" \".join(body for body in df.body)\n",
    "# combining title and body text\n",
    "title_text = \" \".join(title for title in df.title) + body_text\n",
    "\n",
    "# set stop words/letters\n",
    "# stopwords = set(STOPWORDS)\n",
    "# stopwords.add(\"I'm, It's, s, m\")\n",
    "\n",
    "# remove stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "# Exclude stopwords with Python's list comprehension and pandas.DataFrame.apply.\n",
    "df['title'] = df['title'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "df['body'] = df['body'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying profanity filter to text\n",
    "# title_text = remove_bad_words(title_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>created</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>moves tomorrow april 27 2021</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>186</td>\n",
       "      <td>mz6iks</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>5492</td>\n",
       "      <td>1.619496e+09</td>\n",
       "      <td>daily trading discussion thread please keep sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>got feeling whole family going</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>10318</td>\n",
       "      <td>mz27qe</td>\n",
       "      <td>https://v.redd.it/tggz9iaosjv61</td>\n",
       "      <td>238</td>\n",
       "      <td>1.619485e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gme squeeze incoming</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>4845</td>\n",
       "      <td>mz69gk</td>\n",
       "      <td>https://i.redd.it/j0awzqpxnkv61.png</td>\n",
       "      <td>813</td>\n",
       "      <td>1.619495e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>even smallest person change course future</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>28801</td>\n",
       "      <td>myw1zz</td>\n",
       "      <td>https://v.redd.it/1v0moiy9civ61</td>\n",
       "      <td>625</td>\n",
       "      <td>1.619467e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rare copy melvil citadels medias bible</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>5913</td>\n",
       "      <td>myym53</td>\n",
       "      <td>https://i.redd.it/o7pqdntxziv61.jpg</td>\n",
       "      <td>147</td>\n",
       "      <td>1.619475e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title       subreddit  score      id  \\\n",
       "0               moves tomorrow april 27 2021  wallstreetbets    186  mz6iks   \n",
       "1             got feeling whole family going  wallstreetbets  10318  mz27qe   \n",
       "2                       gme squeeze incoming  wallstreetbets   4845  mz69gk   \n",
       "3  even smallest person change course future  wallstreetbets  28801  myw1zz   \n",
       "4     rare copy melvil citadels medias bible  wallstreetbets   5913  myym53   \n",
       "\n",
       "                                                 url  comms_num       created  \\\n",
       "0  https://www.reddit.com/r/wallstreetbets/commen...       5492  1.619496e+09   \n",
       "1                    https://v.redd.it/tggz9iaosjv61        238  1.619485e+09   \n",
       "2                https://i.redd.it/j0awzqpxnkv61.png        813  1.619495e+09   \n",
       "3                    https://v.redd.it/1v0moiy9civ61        625  1.619467e+09   \n",
       "4                https://i.redd.it/o7pqdntxziv61.jpg        147  1.619475e+09   \n",
       "\n",
       "                                                body  \n",
       "0  daily trading discussion thread please keep sh...  \n",
       "1                                                     \n",
       "2                                                     \n",
       "3                                                     \n",
       "4                                                     "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'subreddit', 'score', 'id', 'url', 'comms_num', 'created',\n",
       "       'body'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brainstorming\n",
    "# what do we want to get from this data?\n",
    "# perhaps some insight as to what wsb is thinking/doing in regards to certain stocks\n",
    "# word frequency\n",
    "# sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Word  Frequency\n",
      "0       mvis         34\n",
      "1       yolo         30\n",
      "2        gme         16\n",
      "3     update         16\n",
      "4         dd         13\n",
      "5     market         11\n",
      "6      april          9\n",
      "7      stock          9\n",
      "8          1          8\n",
      "9       2021          7\n",
      "10      like          7\n",
      "11   holding          6\n",
      "12         5          6\n",
      "13    shares          6\n",
      "14     today          6\n",
      "15      apes          6\n",
      "16  earnings          6\n",
      "17  gamestop          5\n",
      "18     since          5\n",
      "19       get          5\n",
      "20     hands          5\n",
      "21     lidar          5\n",
      "22     calls          5\n",
      "23      last          5\n",
      "24         4          5\n",
      "25      moon          5\n",
      "26     tesla          5\n",
      "27    coming          5\n",
      "28      week          5\n",
      "29  tomorrow          4\n"
     ]
    }
   ],
   "source": [
    "# frequency for title\n",
    "title_freq = Counter(\" \".join(df['title']).split()).most_common(30)\n",
    "title_freq = pd.DataFrame(title_freq, columns=['Word', 'Frequency'])\n",
    "print(title_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Word  Frequency\n",
      "0     company        113\n",
      "1       price        101\n",
      "2      market         95\n",
      "3       stock         87\n",
      "4      shares         65\n",
      "5         one         64\n",
      "6        like         63\n",
      "7           1         60\n",
      "8         see         58\n",
      "9        time         58\n",
      "10      going         57\n",
      "11          3         57\n",
      "12       also         56\n",
      "13         10         56\n",
      "14        new         55\n",
      "15         dd         54\n",
      "16      still         53\n",
      "17        get         48\n",
      "18       best         47\n",
      "19      x200b         47\n",
      "20       make         46\n",
      "21       year         46\n",
      "22     people         45\n",
      "23      share         45\n",
      "24       long         45\n",
      "25  companies         45\n",
      "26   earnings         44\n",
      "27    million         44\n",
      "28      could         43\n",
      "29       play         43\n"
     ]
    }
   ],
   "source": [
    "body_freq = Counter(\" \".join(df['body']).split()).most_common(30)\n",
    "body_freq = pd.DataFrame(body_freq, columns=['Word', 'Frequency'])\n",
    "print(body_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is there a a way i can automatically update this \n",
    "# by having the script run everyday at a certain time\n",
    "# and store data to track it over time\n",
    "# see how trends change over time\n",
    "# might help in spotting opportunities earlier\n",
    "# could front run bubbles/capitulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_pass = config(\"PASSWORD\")\n",
    "engine = create_engine(f'postgresql://postgres:{db_pass}@localhost:5432/postgres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "(psycopg2.ProgrammingError) can't adapt type 'Subreddit'\n[SQL: INSERT INTO sample_table (index, title, subreddit, score, id, url, comms_num, created, body) VALUES (%(index)s, %(title)s, %(subreddit)s, %(score)s, %(id)s, %(url)s, %(comms_num)s, %(created)s, %(body)s)]\n[parameters: ({'index': 0, 'title': 'moves tomorrow april 27 2021', 'subreddit': Subreddit(display_name='wallstreetbets'), 'score': 186, 'id': 'mz6iks', 'url': 'https://www.reddit.com/r/wallstreetbets/comments/mz6iks/what_are_your_moves_tomorrow_april_27_2021/', 'comms_num': 5492, 'created': 1619496022.0, 'body': 'daily trading discussion thread please keep shitposting minimum navigate wsb recommend best daily dd dd best daily best weekly discussion best daily  ... (95 characters truncated) ...  weekly earnings discussion thread read rules make sure people follow try meme mode also accessible top bar follow wsb twitter accounts impersonators'}, {'index': 1, 'title': 'got feeling whole family going', 'subreddit': Subreddit(display_name='wallstreetbets'), 'score': 10318, 'id': 'mz27qe', 'url': 'https://v.redd.it/tggz9iaosjv61', 'comms_num': 238, 'created': 1619484837.0, 'body': ''}, {'index': 2, 'title': 'gme squeeze incoming', 'subreddit': Subreddit(display_name='wallstreetbets'), 'score': 4845, 'id': 'mz69gk', 'url': 'https://i.redd.it/j0awzqpxnkv61.png', 'comms_num': 813, 'created': 1619495355.0, 'body': ''}, {'index': 3, 'title': 'even smallest person change course future', 'subreddit': Subreddit(display_name='wallstreetbets'), 'score': 28801, 'id': 'myw1zz', 'url': 'https://v.redd.it/1v0moiy9civ61', 'comms_num': 625, 'created': 1619467293.0, 'body': ''}, {'index': 4, 'title': 'rare copy melvil citadels medias bible', 'subreddit': Subreddit(display_name='wallstreetbets'), 'score': 5913, 'id': 'myym53', 'url': 'https://i.redd.it/o7pqdntxziv61.jpg', 'comms_num': 147, 'created': 1619475233.0, 'body': ''}, {'index': 5, 'title': 'gme technical analysis waves go brrr', 'subreddit': Subreddit(display_name='wallstreetbets'), 'score': 1699, 'id': 'mz5e3m', 'url': 'https://www.reddit.com/r/wallstreetbets/comments/mz5e3m/gme_technical_analysis_waves_go_brrr/', 'comms_num': 228, 'created': 1619493094.0, 'body': \"hi fam fam something going gme may imminent interpretation gme thru wave counting elliotwave refer image first yearly point view accomplished wave 1  ... (1728 characters truncated) ... r shooting blanks think mom told lost chromosome dividing meiosis mitosis per sfwsosa93 phase edit look go literally erection time 40 mins past close\"}, {'index': 6, 'title': 'trying convince family invest using wsb dd', 'subreddit': Subreddit(display_name='wallstreetbets'), 'score': 4547, 'id': 'myxh44', 'url': 'https://v.redd.it/p059q7m8qiv61', 'comms_num': 104, 'created': 1619471933.0, 'body': ''}, {'index': 7, 'title': 'gamestop completes market equity offering program', 'subreddit': Subreddit(display_name='wallstreetbets'), 'score': 839, 'id': 'mz7exv', 'url': 'https://www.stocktitan.net/news/GME/game-stop-completes-at-the-market-equity-offering-v0ie6tw2d6y0.html', 'comms_num': 187, 'created': 1619498394.0, 'body': ''}  ... displaying 10 of 173 total bound parameter sets ...  {'index': 171, 'title': 'cvs technicals', 'subreddit': Subreddit(display_name='wallstreetbets'), 'score': 54, 'id': 'mx4pv4', 'url': 'https://www.reddit.com/r/wallstreetbets/comments/mx4pv4/cvs_technicals/', 'comms_num': 27, 'created': 1619239611.0, 'body': \"unless living rock probably know cvs probably need explain anything anyways think cvs might great opportunity take long position p e ratio cvs pe 13x ... (915 characters truncated) ... might get iv crushed x200b tl dr cvs 80c 5 21 careful earnings soon could iv crush good idea get cheap premiums rn i'm financial advisor i'm retarded\"}, {'index': 172, 'title': '3500 less 5 minutes holding weekend ever learn', 'subreddit': Subreddit(display_name='wallstreetbets'), 'score': 57, 'id': 'mx3yh1', 'url': 'https://i.redd.it/q4rtsmrxczu61.jpg', 'comms_num': 34, 'created': 1619237387.0, 'body': ''})]\n(Background on this error at: http://sqlalche.me/e/14/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Desktop/reddit-scraping/reddit-env/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1685\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1686\u001b[0;31m                     self.dialect.do_executemany(\n\u001b[0m\u001b[1;32m   1687\u001b[0m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/reddit-scraping/reddit-env/lib/python3.8/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py\u001b[0m in \u001b[0;36mdo_executemany\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0mxtras\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_psycopg2_extras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m             context._psycopg2_fetched_rows = xtras.execute_values(\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/reddit-scraping/reddit-env/lib/python3.8/site-packages/psycopg2/extras.py\u001b[0m in \u001b[0;36mexecute_values\u001b[0;34m(cur, sql, argslist, template, page_size, fetch)\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1289\u001b[0;31m             \u001b[0mparts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmogrify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1290\u001b[0m             \u001b[0mparts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProgrammingError\u001b[0m: can't adapt type 'Subreddit'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mProgrammingError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-b936657090a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample_table'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_exists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/reddit-scraping/reddit-env/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   2776\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2778\u001b[0;31m         sql.to_sql(\n\u001b[0m\u001b[1;32m   2779\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2780\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/reddit-scraping/reddit-env/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m    588\u001b[0m         )\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m     pandas_sql.to_sql(\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/reddit-scraping/reddit-env/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   1403\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inf cannot be used with MySQL\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1405\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/reddit-scraping/reddit-env/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   1395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1397\u001b[0;31m             \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1398\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSQLAlchemyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m             \u001b[0;31m# GH34431\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/reddit-scraping/reddit-env/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, chunksize, method)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                 \u001b[0mchunk_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m                 \u001b[0mexec_insert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m     def _query_iterator(\n",
      "\u001b[0;32m~/Desktop/reddit-scraping/reddit-env/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36m_execute_insert\u001b[0;34m(self, conn, keys, data_iter)\u001b[0m\n\u001b[1;32m    746\u001b[0m         \"\"\"\n\u001b[1;32m    747\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute_insert_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/reddit-scraping/reddit-env/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   1199\u001b[0m             )\n\u001b[1;32m   1200\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1201\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_EMPTY_EXECUTION_OPTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/reddit-scraping/reddit-env/lib/python3.8/site-packages/sqlalchemy/sql/elements.py\u001b[0m in \u001b[0;36m_execute_on_connection\u001b[0;34m(self, connection, multiparams, params, execution_options, _force)\u001b[0m\n\u001b[1;32m    311\u001b[0m     ):\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_force\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_execution\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             return connection._execute_clauseelement(\n\u001b[0m\u001b[1;32m    314\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             )\n",
      "\u001b[0;32m~/Desktop/reddit-scraping/reddit-env/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_clauseelement\u001b[0;34m(self, elem, multiparams, params, execution_options)\u001b[0m\n\u001b[1;32m   1388\u001b[0m             \u001b[0mlinting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdialect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler_linting\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mcompiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWARN_LINTING\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m         )\n\u001b[0;32m-> 1390\u001b[0;31m         ret = self._execute_context(\n\u001b[0m\u001b[1;32m   1391\u001b[0m             \u001b[0mdialect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m             \u001b[0mdialect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_ctx_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_compiled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/reddit-scraping/reddit-env/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1749\u001b[0;31m             self._handle_dbapi_exception(\n\u001b[0m\u001b[1;32m   1750\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m             )\n",
      "\u001b[0;32m~/Desktop/reddit-scraping/reddit-env/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   1928\u001b[0m                 \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewraise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1929\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mshould_wrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1930\u001b[0;31m                 util.raise_(\n\u001b[0m\u001b[1;32m   1931\u001b[0m                     \u001b[0msqlalchemy_exception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1932\u001b[0m                 )\n",
      "\u001b[0;32m~/Desktop/reddit-scraping/reddit-env/lib/python3.8/site-packages/sqlalchemy/util/compat.py\u001b[0m in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;31m# credit to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/reddit-scraping/reddit-env/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1684\u001b[0m                             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1686\u001b[0;31m                     self.dialect.do_executemany(\n\u001b[0m\u001b[1;32m   1687\u001b[0m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1688\u001b[0m                     )\n",
      "\u001b[0;32m~/Desktop/reddit-scraping/reddit-env/lib/python3.8/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py\u001b[0m in \u001b[0;36mdo_executemany\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    901\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0mxtras\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_psycopg2_extras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m             context._psycopg2_fetched_rows = xtras.execute_values(\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m                 \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/reddit-scraping/reddit-env/lib/python3.8/site-packages/psycopg2/extras.py\u001b[0m in \u001b[0;36mexecute_values\u001b[0;34m(cur, sql, argslist, template, page_size, fetch)\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1289\u001b[0;31m             \u001b[0mparts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmogrify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1290\u001b[0m             \u001b[0mparts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m         \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProgrammingError\u001b[0m: (psycopg2.ProgrammingError) can't adapt type 'Subreddit'\n[SQL: INSERT INTO sample_table (index, title, subreddit, score, id, url, comms_num, created, body) VALUES (%(index)s, %(title)s, %(subreddit)s, %(score)s, %(id)s, %(url)s, %(comms_num)s, %(created)s, %(body)s)]\n[parameters: ({'index': 0, 'title': 'moves tomorrow april 27 2021', 'subreddit': Subreddit(display_name='wallstreetbets'), 'score': 186, 'id': 'mz6iks', 'url': 'https://www.reddit.com/r/wallstreetbets/comments/mz6iks/what_are_your_moves_tomorrow_april_27_2021/', 'comms_num': 5492, 'created': 1619496022.0, 'body': 'daily trading discussion thread please keep shitposting minimum navigate wsb recommend best daily dd dd best daily best weekly discussion best daily  ... (95 characters truncated) ...  weekly earnings discussion thread read rules make sure people follow try meme mode also accessible top bar follow wsb twitter accounts impersonators'}, {'index': 1, 'title': 'got feeling whole family going', 'subreddit': Subreddit(display_name='wallstreetbets'), 'score': 10318, 'id': 'mz27qe', 'url': 'https://v.redd.it/tggz9iaosjv61', 'comms_num': 238, 'created': 1619484837.0, 'body': ''}, {'index': 2, 'title': 'gme squeeze incoming', 'subreddit': Subreddit(display_name='wallstreetbets'), 'score': 4845, 'id': 'mz69gk', 'url': 'https://i.redd.it/j0awzqpxnkv61.png', 'comms_num': 813, 'created': 1619495355.0, 'body': ''}, {'index': 3, 'title': 'even smallest person change course future', 'subreddit': Subreddit(display_name='wallstreetbets'), 'score': 28801, 'id': 'myw1zz', 'url': 'https://v.redd.it/1v0moiy9civ61', 'comms_num': 625, 'created': 1619467293.0, 'body': ''}, {'index': 4, 'title': 'rare copy melvil citadels medias bible', 'subreddit': Subreddit(display_name='wallstreetbets'), 'score': 5913, 'id': 'myym53', 'url': 'https://i.redd.it/o7pqdntxziv61.jpg', 'comms_num': 147, 'created': 1619475233.0, 'body': ''}, {'index': 5, 'title': 'gme technical analysis waves go brrr', 'subreddit': Subreddit(display_name='wallstreetbets'), 'score': 1699, 'id': 'mz5e3m', 'url': 'https://www.reddit.com/r/wallstreetbets/comments/mz5e3m/gme_technical_analysis_waves_go_brrr/', 'comms_num': 228, 'created': 1619493094.0, 'body': \"hi fam fam something going gme may imminent interpretation gme thru wave counting elliotwave refer image first yearly point view accomplished wave 1  ... (1728 characters truncated) ... r shooting blanks think mom told lost chromosome dividing meiosis mitosis per sfwsosa93 phase edit look go literally erection time 40 mins past close\"}, {'index': 6, 'title': 'trying convince family invest using wsb dd', 'subreddit': Subreddit(display_name='wallstreetbets'), 'score': 4547, 'id': 'myxh44', 'url': 'https://v.redd.it/p059q7m8qiv61', 'comms_num': 104, 'created': 1619471933.0, 'body': ''}, {'index': 7, 'title': 'gamestop completes market equity offering program', 'subreddit': Subreddit(display_name='wallstreetbets'), 'score': 839, 'id': 'mz7exv', 'url': 'https://www.stocktitan.net/news/GME/game-stop-completes-at-the-market-equity-offering-v0ie6tw2d6y0.html', 'comms_num': 187, 'created': 1619498394.0, 'body': ''}  ... displaying 10 of 173 total bound parameter sets ...  {'index': 171, 'title': 'cvs technicals', 'subreddit': Subreddit(display_name='wallstreetbets'), 'score': 54, 'id': 'mx4pv4', 'url': 'https://www.reddit.com/r/wallstreetbets/comments/mx4pv4/cvs_technicals/', 'comms_num': 27, 'created': 1619239611.0, 'body': \"unless living rock probably know cvs probably need explain anything anyways think cvs might great opportunity take long position p e ratio cvs pe 13x ... (915 characters truncated) ... might get iv crushed x200b tl dr cvs 80c 5 21 careful earnings soon could iv crush good idea get cheap premiums rn i'm financial advisor i'm retarded\"}, {'index': 172, 'title': '3500 less 5 minutes holding weekend ever learn', 'subreddit': Subreddit(display_name='wallstreetbets'), 'score': 57, 'id': 'mx3yh1', 'url': 'https://i.redd.it/q4rtsmrxczu61.jpg', 'comms_num': 34, 'created': 1619237387.0, 'body': ''})]\n(Background on this error at: http://sqlalche.me/e/14/f405)"
     ]
    }
   ],
   "source": [
    "df.to_sql('sample_table', engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reddit-env",
   "language": "python",
   "name": "reddit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
